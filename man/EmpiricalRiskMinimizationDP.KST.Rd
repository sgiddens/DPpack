% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/StatModels.R
\name{EmpiricalRiskMinimizationDP.KST}
\alias{EmpiricalRiskMinimizationDP.KST}
\title{Privacy-preserving Empirical Risk Minimization for Regression}
\description{
This class implements differentially private empirical risk
minimization using the objective perturbation technique
\insertCite{Kifer2012}{DPpack}. It is intended to be a framework for
building more specific models via inheritance. See
\code{\link{LinearRegressionDP}} for an example of this type of structure.
}
\details{
A new model object of this class accepts as inputs various functions
and hyperparameters related to the specific regression problem. The model
can then be fit with a dataset X (given as a data.frame), a set of binary
labels y for each row of X, as well as upper and lower bounds on the
possible values for each column of X and for y. In fitting, the model
stores a vector of coefficients coeff which satisfy epsilon-level
differential privacy. These can be released directly, or used in
conjunction with the predict method to predict the label of new datapoints.

Note that in order to guarantee epsilon-level privacy for the empirical
risk minimization model, certain constraints must be satisfied for the
values used to construct the object, as well as for the data used to fit.
Specifically, the following constraints must be met. First, the provided
domain must be a closed convex subset of R^p, where p is the number of
columns of X. Second, if \eqn{L(\theta,X,y) = (1/n)\sum l(\theta,x_i,y_i)}
is the loss function, then \eqn{L} must be convex with a continuous
Hessian. Third, \eqn{||l(\theta,x_i,y_i)||\le} zeta for some constant zeta
for all \eqn{x_i, y_i, \theta}. Fourth, for all \eqn{x_i, y_i, \theta} the
Hessian of \eqn{l(\theta,x_i,y_i)} must be of rank at most one and its
Eigenvalues must be bounded above by some value lambda. Finally, the
regularizer must be convex.
}
\examples{

## ------------------------------------------------
## Method `EmpiricalRiskMinimizationDP.KST$new`
## ------------------------------------------------

# Construct object for linear regression
h <- function(X, coeff) X\%*\%coeff
loss <- function(y.hat, y) (y.hat-y)^2/2
regularizer <- 'l2' # Alternatively, function(coeff) coeff\%*\%coeff/2
eps <- 1
delt <- 1
domain <- list("constraints"=function(coeff) coeff\%*\%coeff-length(coeff),
  "jacobian"=function(coeff) 2*coeff)
# Set p to be the number of predictors desired including intercept term (length of coeff)
zeta <- 2*p^(3/2)
lambda <- p
gamma <- 1
h.gr <- function(X, coeff) t(X)
loss.gr <- function(y.hat, y) y.hat-y
regularizer.gr <- function(coeff) coeff

ermdp <- EmpiricalRiskMinimizationDP.KST$new(h, loss, 'l2', eps, delt,
                                             domain, zeta, lambda,
                                             gamma, h.gr, loss.gr,
                                             regularizer.gr)


## ------------------------------------------------
## Method `EmpiricalRiskMinimizationDP.KST$fit`
## ------------------------------------------------

# Assume X is dataframe meeting assumptions for privacy
# Assume 2 columns of X, with the first being all 1 (for intercept), and
#   the second being between -1 and 1
# Assume y is a matrix with values between -2 and 2
# Assume ermdp is previously constructed object as in $new example
upper.bounds <- c( 1, 1, 2) # Bounds for X and y
lower.bounds <- c(1,-1, -2) # Bounds for X and y
ermdp$fit(X, y, upper.bounds, lower.bounds)
ermdp$coeff # Gets private coefficients


## ------------------------------------------------
## Method `EmpiricalRiskMinimizationDP.KST$predict`
## ------------------------------------------------

# Assume Xtest is a new dataframe of the same form as X from fit
# method example, with true labels ytest
# Also assume ermdp$fit() has already been run on training data
predicted.y <- ermdp$predict(Xtest)

}
\references{
\insertRef{Kifer2012}{DPpack}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{h}}{Hypothesis function of the form h(X, coeff), where X is a matrix
and coeff is a vector or matrix, that returns a column matrix of
predicted labels for each row of X.}

\item{\code{h.gr}}{Function representing the gradient of the hypothesis function
with respect to the values in coeff and of the same form as h. Should
be given such that the ith row of the output represents the gradient of
h with respect to the ith coefficient.}

\item{\code{loss}}{Loss function of the form loss(y.hat, y), where y.hat and y
are matrices, that returns a matrix of the same shape as y.hat and y of
loss function values for the empirical risk minimization model with
predicted labels y.hat and true labels y.}

\item{\code{loss.gr}}{Function representing the gradient of the loss function
with respect to y.hat and of the same form as loss. Should be given
such that the ith row of the output represents the gradient of loss at
the ith set of input values.}

\item{\code{regularizer}}{Regularization function. Must be of the form
regularizer(coeff), where coeff is a vector or matrix, that returns the
value of the regularizer at coeff.}

\item{\code{regularizer.gr}}{Function representing the gradient of the
regularization function with respect to coeff and of the same form as
regularizer. Should return a vector. If regularizer is a string, this
value is ignored.}

\item{\code{eps}}{Positive real number defining the epsilon privacy budget. If
set to Inf, runs algorithm without differential privacy.}

\item{\code{delt}}{Nonnegative real number defining the delta parameter for
approximate differential privacy. If set to 0, pure differential
privacy is used.}

\item{\code{domain}}{List of functions representing the constraints on the
search space for the objective perturbation algorithm. Must contain two
function, labeled "constraints" and "jacobian", respectively. The
"constraints" function accepts a vector of coefficients from the search
space and returns a value such that the value is \eqn{\le 0} if and
only if the input coefficient vector is within the constrained search
space. The "jacobian" function also accepts a vector of coefficients
and returns the Jacobian of the constraint function. For example, in
linear regression, the coefficient vector \eqn{\theta} is assumed to
satisfy \eqn{||\theta||_2 \le sqrt(p)}, where \eqn{p} is the length of
\eqn{\theta} \insertCite{Kifer2012}{DPpack}. So, domain could be
defined as \code{domain <- list("constraints"=function(coeff) coeff\%*\%coeff-length(coeff), "jacobian"=function(coeff) 2*coeff)}.}

\item{\code{zeta}}{Positive real number corresponding to the upper bound of the
2-norm of the gradient of the loss function with respect to the
coefficient vector, i.e. \eqn{||l(\theta,x_i,y_i)||\le} zeta for some
constant zeta for all \eqn{x_i, y_i, \theta}.}

\item{\code{lambda}}{Positive real number corresponding to the upper bound of
the Eigenvalues of the Hessian of \eqn{l(\theta,x_i,y_i)} for all
\eqn{x_i, y_i, \theta}.}

\item{\code{gamma}}{Nonnegative real number representing the regularization
constant.}

\item{\code{coeff}}{Numeric vector of coefficients for the model.}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{EmpiricalRiskMinimizationDP.KST$new()}}
\item \href{#method-fit}{\code{EmpiricalRiskMinimizationDP.KST$fit()}}
\item \href{#method-predict}{\code{EmpiricalRiskMinimizationDP.KST$predict()}}
\item \href{#method-clone}{\code{EmpiricalRiskMinimizationDP.KST$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Create a new EmpiricalRiskMinimizationDP.KST object.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EmpiricalRiskMinimizationDP.KST$new(
  h,
  loss,
  regularizer,
  eps,
  delt,
  domain,
  zeta,
  lambda,
  gamma,
  h.gr = NULL,
  loss.gr = NULL,
  regularizer.gr = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{h}}{Hypothesis function. Must have form as given in h field
description.}

\item{\code{loss}}{Loss function. Must have form as given in loss field
description. Additionally, to ensure differential privacy, it must be
convex, \eqn{||l(\theta,x_i,y_i)||\le} zeta for some constant zeta for
all \eqn{x_i, y_i, \theta}, and for all \eqn{x_i, y_i, \theta} the
Hessian of \eqn{l(\theta,x_i,y_i)} must be of rank at most one and its
Eigenvalues must be bounded above by some value lambda.}

\item{\code{regularizer}}{String or regularization function. If a string, must
be 'l2', indicating to use l2 regularization. If a function, must have
form as given in regularizer field description. Additionally, in order
to ensure differential privacy, the function must be 1-strongly convex
and doubly differentiable.}

\item{\code{eps}}{Positive real number defining the epsilon privacy budget. If
set to Inf, runs algorithm without differential privacy.}

\item{\code{delt}}{Nonnegative real number defining the delta parameter for
approximate differential privacy. If set to 0, pure differential
privacy is used.}

\item{\code{domain}}{List of functions representing the constraints on the
search space for the objective perturbation algorithm of form as given
in domain field description.}

\item{\code{zeta}}{Positive real number corresponding to the upper bound of the
2-norm of the gradient of the loss function with respect to the
coefficient vector, i.e. \eqn{||l(\theta,x_i,y_i)||\le} zeta for some
constant zeta for all \eqn{x_i, y_i, \theta}.}

\item{\code{lambda}}{Positive real number corresponding to the upper bound of
the Eigenvalues of the Hessian of \eqn{l(\theta,x_i,y_i)} for all
\eqn{x_i, y_i, \theta}.}

\item{\code{gamma}}{Nonnegative real number representing the regularization
constant.}

\item{\code{h.gr}}{Optional function representing the gradient of the hypothesis
function with respect to the values in coeff. Must have form as given
in h.gr field description. If not given, gradients are not used to
compute the coefficient values in fitting the model.}

\item{\code{loss.gr}}{Optional function representing the gradient of the loss
function with respect to y.hat. Must have form as given in loss.gr
field description. If not given, gradients are not used to compute the
coefficient values in fitting the model.}

\item{\code{regularizer.gr}}{Optional function representing the gradient of the
regularizer function function with respect to coeff. Must have form as
given in regularizer.gr field description. If not given, gradients are
not used to compute the coefficient values in fitting the model.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A new EmpiricalRiskMinimizationDP.KST object.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Construct object for linear regression
h <- function(X, coeff) X\%*\%coeff
loss <- function(y.hat, y) (y.hat-y)^2/2
regularizer <- 'l2' # Alternatively, function(coeff) coeff\%*\%coeff/2
eps <- 1
delt <- 1
domain <- list("constraints"=function(coeff) coeff\%*\%coeff-length(coeff),
  "jacobian"=function(coeff) 2*coeff)
# Set p to be the number of predictors desired including intercept term (length of coeff)
zeta <- 2*p^(3/2)
lambda <- p
gamma <- 1
h.gr <- function(X, coeff) t(X)
loss.gr <- function(y.hat, y) y.hat-y
regularizer.gr <- function(coeff) coeff

ermdp <- EmpiricalRiskMinimizationDP.KST$new(h, loss, 'l2', eps, delt,
                                             domain, zeta, lambda,
                                             gamma, h.gr, loss.gr,
                                             regularizer.gr)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-fit"></a>}}
\if{latex}{\out{\hypertarget{method-fit}{}}}
\subsection{Method \code{fit()}}{
Fit the differentially private emprirical risk minimization
model. The function runs the objective perturbation algorithm
\insertCite{Kifer2012}{DPpack} to generate an objective function. A
numerical constrained optimization method is then run to find optimal
coefficients for fitting the model given the training data and
hyperparameters. The \code{\link{nloptr}} function is used. If h.gr,
loss.gr, and regularizer.gr are all given in the construction of the
object, the gradient of the objective function and the Jacobian of the
constraint function are utilized for the algorithm, and the NLOPT_LD_MMA
method is used. If one or more of these gradient functions are not given,
the NLOPT_LN_COBYLA method is used. The resulting privacy-preserving
coefficients are stored in coeff.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EmpiricalRiskMinimizationDP.KST$fit(
  X,
  y,
  upper.bounds = NULL,
  lower.bounds = NULL,
  add.bias = FALSE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{Dataframe of data to be fit.}

\item{\code{y}}{Vector or matrix of true labels for each row of X.}

\item{\code{upper.bounds}}{Optional vector of length ncol(X)+1 giving upper bounds
on the values in each column of X and the values in y. The last value in
the vector is assumed to be the upper bound on y, while the first ncol(X)
values are assumed to be in the same order as the corresponding columns
of X. If NULL (default), the values are computed to be the maximum values
in the data, which results in additional privacy loss. Any value in the
columns of X and y larger than the corresponding upper bound is clipped
at the bound.}

\item{\code{lower.bounds}}{Optional vector of length ncol(X)+1 giving lower bounds
on the values in each column of X and the values in y. The last value in
the vector is assumed to be the lower bound on y, while the first ncol(X)
values are assumed to be in the same order as the corresponding columns
of X. If NULL (default), the values are computed to be the minimum values
in the data, which results in additional privacy loss. Any value in the
columns of X and y smaller than the corresponding lower bound is clipped
at the bound.}

\item{\code{add.bias}}{Boolean indicating whether to add a bias term to X.
Defaults to FALSE.}
}
\if{html}{\out{</div>}}
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assume X is dataframe meeting assumptions for privacy
# Assume 2 columns of X, with the first being all 1 (for intercept), and
#   the second being between -1 and 1
# Assume y is a matrix with values between -2 and 2
# Assume ermdp is previously constructed object as in $new example
upper.bounds <- c( 1, 1, 2) # Bounds for X and y
lower.bounds <- c(1,-1, -2) # Bounds for X and y
ermdp$fit(X, y, upper.bounds, lower.bounds)
ermdp$coeff # Gets private coefficients

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-predict"></a>}}
\if{latex}{\out{\hypertarget{method-predict}{}}}
\subsection{Method \code{predict()}}{
Predict y values for given X using the fitted coefficients.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EmpiricalRiskMinimizationDP.KST$predict(X, add.bias = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{X}}{Dataframe of data on which to make predictions. Must be of same
form as X used to fit coefficients.}

\item{\code{add.bias}}{Boolean indicating whether to add a bias term to X.
Defaults to FALSE. If add.bias was set to TRUE when fitting the
coefficients, add.bias should be set to TRUE for predictions.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Matrix of predicted y values corresponding to each row of X.
}
\subsection{Examples}{
\if{html}{\out{<div class="r example copy">}}
\preformatted{# Assume Xtest is a new dataframe of the same form as X from fit
# method example, with true labels ytest
# Also assume ermdp$fit() has already been run on training data
predicted.y <- ermdp$predict(Xtest)

}
\if{html}{\out{</div>}}

}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{EmpiricalRiskMinimizationDP.KST$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
